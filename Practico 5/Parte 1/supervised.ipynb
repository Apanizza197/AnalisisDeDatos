{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerias \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Para mostrar el arbol de decision\n",
    "from sklearn.tree import export_graphviz\n",
    "from six import StringIO\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset\n",
    "star_data = pd.read_csv('estrellas.csv')\n",
    "# star_data.head()\n",
    "\n",
    "# Verificar si hay valores nulos\n",
    "# print(star_data.isnull().sum())\n",
    "\n",
    "# No hay valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = star_data.drop(columns='Spectral Class')\n",
    "y = star_data['Spectral Class']\n",
    "\n",
    "# Dividir en train, test y validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar_variables_categoricas(data):\n",
    "    '''Preprocesar variables categoricas'''\n",
    "    # Obtener dummies de columnas Star type, Star category, Star color\n",
    "    dummies = pd.get_dummies(data[['Star type', 'Star category', 'Star color']])\n",
    "    # Eliminar columnas originales\n",
    "    data.drop(columns=['Star type', 'Star category', 'Star color'], inplace=True)\n",
    "    # Concatenar dummies\n",
    "    data = pd.concat([data, dummies], axis=1)\n",
    "    return data\n",
    "\n",
    "X_train = preprocesar_variables_categoricas(X_train)\n",
    "X_val = preprocesar_variables_categoricas(X_val)\n",
    "X_test = preprocesar_variables_categoricas(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all columns in X_train, X_val and X_test\n",
    "all_columns = set(X_train.columns).union(set(X_val.columns)).union(set(X_test.columns))\n",
    "\n",
    "# Add missing columns to X_train, X_val and X_test\n",
    "for column in all_columns:\n",
    "    if column not in X_train.columns:\n",
    "        X_train[column] = False\n",
    "    if column not in X_val.columns:\n",
    "        X_val[column] = False\n",
    "    if column not in X_test.columns:\n",
    "        X_test[column] = False\n",
    "\n",
    "# Reorder columns\n",
    "X_train = X_train[list(all_columns)]\n",
    "X_val = X_val[list(all_columns)]\n",
    "X_test = X_test[list(all_columns)]\n",
    "\n",
    "features = list(X_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar datos\n",
    "def normalizar_datos(data):\n",
    "    '''Normalizar datos'''\n",
    "    scaler = StandardScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "    return data\n",
    "\n",
    "X_train = normalizar_datos(X_train)\n",
    "X_val = normalizar_datos(X_val)\n",
    "X_test = normalizar_datos(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluar accuracy, precision, recall y F1\n",
    "def obtener_metricas_evaluacion(y_real, y_predicho):\n",
    "    '''Obtener metricas de evaluacion'''\n",
    "\n",
    "    matrix_confusion = confusion_matrix(y_real, y_predicho)\n",
    "    print('Accuracy:', get_accuracy(matrix_confusion))\n",
    "    print('Precision:', get_precision(matrix_confusion))\n",
    "    print('Recall:', get_recall(matrix_confusion))\n",
    "    print('F1:', get_f1(matrix_confusion))\n",
    "    \n",
    "    sns.heatmap(matrix_confusion, annot=True, fmt='d')\n",
    "    plt.xlabel('Predicho')\n",
    "    plt.ylabel('Real')\n",
    "    plt.show()\n",
    "\n",
    "def get_accuracy(matrix_confusion):\n",
    "    '''Obtener accuracy'''\n",
    "    sum = 0\n",
    "    for i in range(len(matrix_confusion)):\n",
    "        sum += matrix_confusion[i][i]\n",
    "    return sum / matrix_confusion.sum()\n",
    "\n",
    "def get_precision(matrix_confusion):\n",
    "    '''Obtener precision'''\n",
    "    columns = []\n",
    "    for i in range(len(matrix_confusion)):\n",
    "        if matrix_confusion[i,:].sum() == 0:\n",
    "            columns.append(0)\n",
    "        else:\n",
    "            columns.append(matrix_confusion[i][i] / matrix_confusion[i, :].sum())\n",
    "    return columns\n",
    "\n",
    "def get_recall(matrix_confusion):\n",
    "    '''Obtener recall'''\n",
    "    rows = []\n",
    "    for i in range(len(matrix_confusion)):\n",
    "        if matrix_confusion[:,i].sum() == 0:\n",
    "            rows.append(0)\n",
    "        else:\n",
    "            rows.append(matrix_confusion[i][i] / matrix_confusion[:, i].sum())\n",
    "    return rows\n",
    "\n",
    "def get_f1(matrix_confusion):\n",
    "    '''Obtener F1'''\n",
    "    precision = get_precision(matrix_confusion)\n",
    "    recall = get_recall(matrix_confusion)\n",
    "    f1 = []\n",
    "    for i in range(len(precision)):\n",
    "        if precision[i] + recall[i] == 0:\n",
    "            f1.append(0)\n",
    "        else:\n",
    "            f1.append(2 * (precision[i] * recall[i]) / (precision[i] + recall[i]))\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un dataframe para almacenar los resultados\n",
    "resultados = pd.DataFrame(columns=['Modelo', 'Accuracy', 'Precision', 'Recall', 'F1', 'Description'])\n",
    "\n",
    "def agregar_resultados(modelo_nombre, y_real, y_predicho, descripcion=''):\n",
    "    '''Agregar resultados al dataframe'''\n",
    "    matrix_confusion = confusion_matrix(y_real, y_predicho)\n",
    "    accuracy = get_accuracy(matrix_confusion)\n",
    "    precision = np.mean(get_precision(matrix_confusion))\n",
    "    recall = np.mean(get_recall(matrix_confusion))\n",
    "    f1 = np.mean(get_f1(matrix_confusion))\n",
    "    \n",
    "    resultados.loc[len(resultados)] = [modelo_nombre, accuracy, precision, recall, f1, descripcion]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_random_forest = RandomForestClassifier()\n",
    "modelo_random_forest.fit(X_train, y_train)\n",
    "y_pred = modelo_random_forest.predict(X_val)\n",
    "\n",
    "agregar_resultados('Random Forest', y_val, y_pred, 'n_estimators=100, max_depth=None')\n",
    "\n",
    "modelo_random_forest = RandomForestClassifier(n_estimators=200)\n",
    "modelo_random_forest.fit(X_train, y_train)\n",
    "y_pred = modelo_random_forest.predict(X_val)\n",
    "\n",
    "agregar_resultados('Random Forest', y_val, y_pred, 'n_estimators=200, max_depth=None')\n",
    "\n",
    "modelo_random_forest = RandomForestClassifier(n_estimators=200, max_depth=10)\n",
    "modelo_random_forest.fit(X_train, y_train)\n",
    "y_pred = modelo_random_forest.predict(X_val)\n",
    "\n",
    "agregar_resultados('Random Forest', y_val, y_pred, 'n_estimators=100, max_depth=10')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelo Regresion Logistica\n",
    "modelo_regresion_logistica = LogisticRegression()\n",
    "modelo_regresion_logistica.fit(X_train, y_train)\n",
    "y_pred = modelo_regresion_logistica.predict(X_val)\n",
    "\n",
    "agregar_resultados('Regresion Logistica', y_val, y_pred, 'max_iter=100, C=1')\n",
    "\n",
    "# Entrenar modelo Regresion Logistica\n",
    "modelo_regresion_logistica = LogisticRegression(max_iter=200)\n",
    "modelo_regresion_logistica.fit(X_train, y_train)\n",
    "y_pred = modelo_regresion_logistica.predict(X_val)\n",
    "\n",
    "agregar_resultados('Regresion Logistica', y_val, y_pred, 'max_iter=200, C=1')\n",
    "\n",
    "# Entrenar modelo Regresion Logistica\n",
    "modelo_regresion_logistica = LogisticRegression(max_iter=200, C=0.1)\n",
    "modelo_regresion_logistica.fit(X_train, y_train)\n",
    "y_pred = modelo_regresion_logistica.predict(X_val)\n",
    "\n",
    "agregar_resultados('Regresion Logistica', y_val, y_pred, 'max_iter=200, C=0.1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_svm = SVC()\n",
    "modelo_svm.fit(X_train, y_train)\n",
    "y_pred = modelo_svm.predict(X_val)\n",
    "\n",
    "agregar_resultados('SVM', y_val, y_pred, 'C=1, kernel=rbf')\n",
    "\n",
    "modelo_svm = SVC(C=0.1)\n",
    "modelo_svm.fit(X_train, y_train)\n",
    "y_pred = modelo_svm.predict(X_val)\n",
    "\n",
    "agregar_resultados('SVM', y_val, y_pred, 'C=0.1, kernel=rbf')\n",
    "\n",
    "modelo_svm = SVC(C=0.1, kernel='linear')\n",
    "modelo_svm.fit(X_train, y_train)\n",
    "y_pred = modelo_svm.predict(X_val)\n",
    "\n",
    "agregar_resultados('SVM', y_val, y_pred, 'C=0.1, kernel=linear')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_decision_tree = DecisionTreeClassifier()\n",
    "modelo_decision_tree.fit(X_train, y_train)\n",
    "y_pred = modelo_decision_tree.predict(X_val)\n",
    "\n",
    "agregar_resultados('Decision Tree', y_val, y_pred, 'max_depth=None, min_samples_split=2')\n",
    "\n",
    "modelo_decision_tree = DecisionTreeClassifier(max_depth=10)\n",
    "modelo_decision_tree.fit(X_train, y_train)\n",
    "y_pred = modelo_decision_tree.predict(X_val)\n",
    "\n",
    "agregar_resultados('Decision Tree', y_val, y_pred, 'max_depth=10, min_samples_split=2')\n",
    "\n",
    "modelo_decision_tree = DecisionTreeClassifier(max_depth=10, min_samples_split=5)\n",
    "modelo_decision_tree.fit(X_train, y_train)\n",
    "y_pred = modelo_decision_tree.predict(X_val)\n",
    "\n",
    "agregar_resultados('Decision Tree', y_val, y_pred, 'max_depth=10, min_samples_split=5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.694363</td>\n",
       "      <td>0.701810</td>\n",
       "      <td>n_estimators=100, max_depth=None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.730011</td>\n",
       "      <td>0.724960</td>\n",
       "      <td>n_estimators=200, max_depth=None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.713807</td>\n",
       "      <td>0.704852</td>\n",
       "      <td>n_estimators=100, max_depth=10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Regresion Logistica</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.670139</td>\n",
       "      <td>0.727083</td>\n",
       "      <td>0.677414</td>\n",
       "      <td>max_iter=100, C=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Regresion Logistica</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.670139</td>\n",
       "      <td>0.727083</td>\n",
       "      <td>0.677414</td>\n",
       "      <td>max_iter=200, C=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Regresion Logistica</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.742511</td>\n",
       "      <td>0.691495</td>\n",
       "      <td>max_iter=200, C=0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.628472</td>\n",
       "      <td>0.721065</td>\n",
       "      <td>0.626803</td>\n",
       "      <td>C=1, kernel=rbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.402778</td>\n",
       "      <td>0.351852</td>\n",
       "      <td>0.365079</td>\n",
       "      <td>C=0.1, kernel=rbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.730937</td>\n",
       "      <td>0.639114</td>\n",
       "      <td>C=0.1, kernel=linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.534722</td>\n",
       "      <td>0.529762</td>\n",
       "      <td>0.513528</td>\n",
       "      <td>max_depth=None, min_samples_split=2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.465986</td>\n",
       "      <td>0.452072</td>\n",
       "      <td>max_depth=10, min_samples_split=2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.534722</td>\n",
       "      <td>0.510714</td>\n",
       "      <td>0.503302</td>\n",
       "      <td>max_depth=10, min_samples_split=5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.628472</td>\n",
       "      <td>0.721065</td>\n",
       "      <td>0.626803</td>\n",
       "      <td>C=1, kernel=rbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.670139</td>\n",
       "      <td>0.730324</td>\n",
       "      <td>0.678192</td>\n",
       "      <td>C=2, kernel=rbf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.696545</td>\n",
       "      <td>0.667599</td>\n",
       "      <td>C=2, kernel=linear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Modelo  Accuracy  Precision    Recall        F1  \\\n",
       "0         Random Forest  0.871795   0.715278  0.694363  0.701810   \n",
       "1         Random Forest  0.897436   0.736111  0.730011  0.724960   \n",
       "2         Random Forest  0.871795   0.715278  0.713807  0.704852   \n",
       "3   Regresion Logistica  0.846154   0.670139  0.727083  0.677414   \n",
       "4   Regresion Logistica  0.846154   0.670139  0.727083  0.677414   \n",
       "5   Regresion Logistica  0.871795   0.680556  0.742511  0.691495   \n",
       "6                   SVM  0.820513   0.628472  0.721065  0.626803   \n",
       "7                   SVM  0.666667   0.402778  0.351852  0.365079   \n",
       "8                   SVM  0.846154   0.638889  0.730937  0.639114   \n",
       "9         Decision Tree  0.692308   0.534722  0.529762  0.513528   \n",
       "10        Decision Tree  0.717949   0.458333  0.465986  0.452072   \n",
       "11        Decision Tree  0.692308   0.534722  0.510714  0.503302   \n",
       "12                  SVM  0.820513   0.628472  0.721065  0.626803   \n",
       "13                  SVM  0.846154   0.670139  0.730324  0.678192   \n",
       "14                  SVM  0.846154   0.680556  0.696545  0.667599   \n",
       "\n",
       "                            Description  \n",
       "0      n_estimators=100, max_depth=None  \n",
       "1      n_estimators=200, max_depth=None  \n",
       "2        n_estimators=100, max_depth=10  \n",
       "3                     max_iter=100, C=1  \n",
       "4                     max_iter=200, C=1  \n",
       "5                   max_iter=200, C=0.1  \n",
       "6                       C=1, kernel=rbf  \n",
       "7                     C=0.1, kernel=rbf  \n",
       "8                  C=0.1, kernel=linear  \n",
       "9   max_depth=None, min_samples_split=2  \n",
       "10    max_depth=10, min_samples_split=2  \n",
       "11    max_depth=10, min_samples_split=5  \n",
       "12                      C=1, kernel=rbf  \n",
       "13                      C=2, kernel=rbf  \n",
       "14                   C=2, kernel=linear  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gurobienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
